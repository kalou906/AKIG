# üîÑ GUIDE COMPLET D'IMPORT DES DONN√âES LEGACY - AKIG

## üìã Vue d'ensemble

Ce syst√®me ultra-professionnel permet d'importer automatiquement toutes vos donn√©es de l'ancien logiciel (loyers, paiements, immeubles, locataires, contrats, etc.) vers le nouveau syst√®me AKIG.

**Processus en 3 √©tapes** :
1. **Analyse** : D√©tecte automatiquement le format et cat√©gorise les donn√©es
2. **Validation** : V√©rifie la qualit√©, nettoie et transforme les donn√©es
3. **Import** : Importe dans PostgreSQL avec gestion d'erreurs et rollback

---

## üéØ Formats Support√©s

Le syst√®me d√©tecte automatiquement et traite :

| Format | Extension | Description |
|--------|-----------|-------------|
| **SQL Dump** | `.sql` | Export PostgreSQL/MySQL standard |
| **SQLite** | `.db`, `.sqlite`, `.sqlite3` | Base SQLite |
| **JSON** | `.json` | Export JSON structur√© |
| **CSV** | `.csv` | Fichiers CSV (d√©tection auto du d√©limiteur) |
| **Excel** | `.xls`, `.xlsx` | Classeurs Excel |
| **Archive** | `.zip`, `.tar`, `.gz` | Archives compress√©es |
| **R√©pertoire** | Dossier | Collection de fichiers |

---

## üì¶ Installation des D√©pendances

```powershell
# Aller dans le r√©pertoire du projet
cd c:\AKIG

# Installer les d√©pendances Python
pip install psycopg2-binary

# Les autres d√©pendances sont natives Python 3
```

---

## üöÄ √âTAPE 1 : Analyse de l'Archive

### Placer votre archive

Copiez votre fichier de sauvegarde dans le projet :

```powershell
# Exemple : copier votre backup
copy "C:\Mes Documents\backup_ancien_logiciel.sql" "c:\AKIG\data\legacy-backup.sql"
```

### Lancer l'analyse

```powershell
# Analyser l'archive
python scripts/legacy-import/analyze-archive.py data/legacy-backup.sql
```

**Ce que fait l'analyseur** :
- ‚úÖ D√©tecte automatiquement le format
- ‚úÖ Identifie les tables/collections
- ‚úÖ Compte les enregistrements par cat√©gorie
- ‚úÖ Extrait des √©chantillons de donn√©es
- ‚úÖ G√©n√®re un rapport JSON d√©taill√©

### R√©sultat

Un fichier `analysis-report.json` est cr√©√© dans `scripts/legacy-import/` :

```json
{
  "format": "sql",
  "categories": {
    "proprietaires": {"count": 155, "sample": [...]},
    "immeubles": {"count": 89, "sample": [...]},
    "locaux": {"count": 342, "sample": [...]},
    "locataires": {"count": 1200, "sample": [...]},
    "contrats": {"count": 856, "sample": [...]},
    "paiements": {"count": 15430, "sample": [...]}
  },
  "statistics": {
    "total_inserts": 18072,
    "tables": {...}
  }
}
```

---

## üè∑Ô∏è √âTAPE 2 : Cat√©gorisation et Validation

### Lancer la validation

```powershell
# Cat√©goriser et valider les donn√©es
python scripts/legacy-import/categorize-data.py scripts/legacy-import/analysis-report.json
```

**Ce que fait le cat√©goriseur** :
- ‚úÖ Valide tous les champs requis
- ‚úÖ V√©rifie les formats (emails, t√©l√©phones, dates)
- ‚úÖ Valide les montants (positifs, format num√©rique)
- ‚úÖ V√©rifie les contraintes FK (r√©f√©rences entre tables)
- ‚úÖ Transforme vers le nouveau sch√©ma
- ‚úÖ G√©n√®re des fichiers JSON propres par cat√©gorie

### R√®gles de Validation

#### Propri√©taires
- **Requis** : `nom`, `contact`
- **Optionnels** : `email`, `telephone`, `adresse`
- **Validations** : Format email, format t√©l√©phone

#### Immeubles
- **Requis** : `nom`, `adresse`
- **Optionnels** : `proprietaire_id`, `ville`
- **FK** : `proprietaire_id` ‚Üí `proprietaires`

#### Locaux (Propri√©t√©s)
- **Requis** : `nom`, `type`
- **Optionnels** : `surface`, `pieces`, `immeuble_id`
- **FK** : `immeuble_id` ‚Üí `immeubles`
- **Types valides** : appartement, maison, bureau, commerce

#### Locataires
- **Requis** : `prenom`, `nom`
- **Optionnels** : `email`, `telephone`, `adresse`
- **Validations** : Format email, format t√©l√©phone

#### Contrats
- **Requis** : `local_id`, `locataire_id`, `date_debut`, `loyer`
- **Optionnels** : `date_fin`, `charges`, `depot_garantie`
- **FK** : `local_id` ‚Üí `locaux`, `locataire_id` ‚Üí `locataires`
- **Validations** : Dates valides, montants positifs

#### Paiements
- **Requis** : `contrat_id`, `montant`, `date`
- **Optionnels** : `methode`, `reference`
- **FK** : `contrat_id` ‚Üí `contrats`
- **M√©thodes valides** : especes, cheque, virement, carte, mobile_money

### R√©sultat

Fichiers JSON valid√©s dans `scripts/legacy-import/categorized-data/` :
```
categorized-data/
‚îú‚îÄ‚îÄ proprietaires.json      # Propri√©taires valid√©s
‚îú‚îÄ‚îÄ immeubles.json          # Immeubles valid√©s
‚îú‚îÄ‚îÄ locaux.json             # Locaux/propri√©t√©s valid√©s
‚îú‚îÄ‚îÄ locataires.json         # Locataires valid√©s
‚îú‚îÄ‚îÄ contrats.json           # Contrats valid√©s
‚îú‚îÄ‚îÄ paiements.json          # Paiements valid√©s
‚îî‚îÄ‚îÄ charges.json            # Charges valid√©es
```

Rapport de validation `validation-report.json` :
```json
{
  "total_records": 18072,
  "valid_records": 17856,
  "invalid_records": 216,
  "warnings_count": 342,
  "by_category": {
    "proprietaires": {"total": 155, "valid": 153, "invalid": 2},
    "contrats": {"total": 856, "valid": 842, "invalid": 14},
    ...
  }
}
```

---

## üíæ √âTAPE 3 : Import dans PostgreSQL

### Pr√©parer la base de donn√©es

```powershell
# S'assurer que PostgreSQL est lanc√©
# V√©rifier que les tables existent (migrations ex√©cut√©es)
```

### Mode DRY-RUN (test sans modification)

**RECOMMAND√â** : Testez d'abord sans rien modifier :

```powershell
python scripts/legacy-import/import-to-postgres.py `
  "postgresql://akig_user:your_password@localhost:5432/akig_db" `
  "scripts/legacy-import/categorized-data" `
  --dry-run
```

Cela simule l'import et affiche :
- ‚úÖ Les requ√™tes SQL qui seraient ex√©cut√©es
- ‚úÖ Le nombre d'enregistrements par table
- ‚úÖ Les erreurs potentielles

### Import R√âEL

Une fois satisfait du dry-run :

```powershell
python scripts/legacy-import/import-to-postgres.py `
  "postgresql://akig_user:your_password@localhost:5432/akig_db" `
  "scripts/legacy-import/categorized-data"
```

**Ordre d'import (respecte les FK)** :
1. `proprietaires` ‚Üí `owners`
2. `immeubles` ‚Üí `sites`
3. `locaux` ‚Üí `properties`
4. `locataires` ‚Üí `tenants`
5. `contrats` ‚Üí `contracts`
6. `loyers` ‚Üí `rent_payments`
7. `paiements` ‚Üí `payments`
8. `charges` ‚Üí `charges`

**S√©curit√©s** :
- ‚úÖ Transactions atomiques (tout ou rien)
- ‚úÖ Rollback automatique en cas d'erreur
- ‚úÖ Import par batch (100 records √† la fois)
- ‚úÖ Gestion des doublons (ON CONFLICT DO UPDATE)
- ‚úÖ Logs d√©taill√©s de chaque op√©ration

### R√©sultat

Rapport d'import `import-report.json` :
```json
{
  "imported": {
    "proprietaires": {"table": "owners", "count": 153, "errors": 0},
    "immeubles": {"table": "sites", "count": 87, "errors": 0},
    "locaux": {"table": "properties", "count": 338, "errors": 4},
    "locataires": {"table": "tenants", "count": 1198, "errors": 2},
    "contrats": {"table": "contracts", "count": 842, "errors": 0},
    "paiements": {"table": "payments", "count": 15234, "errors": 196}
  }
}
```

---

## üéØ Workflow Complet - Exemple R√©el

### Cas d'usage : Backup SQL de l'ancien syst√®me

```powershell
# 1. Vous avez un fichier backup_immobilier.sql

# 2. Analyser
python scripts/legacy-import/analyze-archive.py data/backup_immobilier.sql
# ‚úÖ R√©sultat : 6 cat√©gories trouv√©es, 18K enregistrements

# 3. Valider et cat√©goriser
python scripts/legacy-import/categorize-data.py scripts/legacy-import/analysis-report.json
# ‚úÖ R√©sultat : 17.8K valides, 200 invalides, 342 warnings

# 4. V√©rifier les fichiers JSON g√©n√©r√©s
ls scripts/legacy-import/categorized-data/
# proprietaires.json, immeubles.json, locaux.json, ...

# 5. Test d'import (DRY-RUN)
python scripts/legacy-import/import-to-postgres.py `
  $env:DATABASE_URL `
  "scripts/legacy-import/categorized-data" `
  --dry-run
# ‚úÖ V√©rifie que tout fonctionne sans modifier la base

# 6. Import R√âEL
python scripts/legacy-import/import-to-postgres.py `
  $env:DATABASE_URL `
  "scripts/legacy-import/categorized-data"
# ‚úÖ 17.8K enregistrements import√©s avec succ√®s !

# 7. V√©rifier dans la base
psql -U akig_user -d akig_db -c "SELECT COUNT(*) FROM owners"
psql -U akig_user -d akig_db -c "SELECT COUNT(*) FROM contracts"
```

---

## üîß Mapping des Champs

### Propri√©taires (owners)

| Ancien champ | Nouveau champ | Type |
|--------------|---------------|------|
| `id` | `id` | INTEGER |
| `nom` | `company_name` | VARCHAR |
| `contact` | `contact_name` | VARCHAR |
| `email` | `email` | VARCHAR |
| `telephone` | `phone` | VARCHAR |
| `adresse` | `address` | TEXT |

### Immeubles (sites)

| Ancien champ | Nouveau champ | Type |
|--------------|---------------|------|
| `id` | `id` | INTEGER |
| `nom` | `name` | VARCHAR |
| `adresse` | `address` | TEXT |
| `proprietaire_id` | `owner_id` | INTEGER (FK) |

### Locaux (properties)

| Ancien champ | Nouveau champ | Type |
|--------------|---------------|------|
| `id` | `id` | INTEGER |
| `nom` | `name` | VARCHAR |
| `type` | `type` | VARCHAR |
| `surface` | `surface_area` | DECIMAL |
| `pieces` | `rooms` | INTEGER |
| `immeuble_id` | `site_id` | INTEGER (FK) |

### Contrats (contracts)

| Ancien champ | Nouveau champ | Type |
|--------------|---------------|------|
| `id` | `id` | INTEGER |
| `local_id` | `property_id` | INTEGER (FK) |
| `locataire_id` | `tenant_id` | INTEGER (FK) |
| `date_debut` | `start_date` | DATE |
| `date_fin` | `end_date` | DATE |
| `loyer` | `rent_amount` | DECIMAL |
| `depot_garantie` | `security_deposit` | DECIMAL |

### Paiements (payments)

| Ancien champ | Nouveau champ | Type |
|--------------|---------------|------|
| `id` | `id` | INTEGER |
| `contrat_id` | `contract_id` | INTEGER (FK) |
| `montant` | `amount` | DECIMAL |
| `date` | `payment_date` | DATE |
| `methode` | `payment_method` | VARCHAR |

---

## ‚ö†Ô∏è Gestion des Erreurs

### Erreurs Communes

#### 1. Table manquante
```
‚ùå Table manquante: owners
```
**Solution** : Ex√©cuter les migrations avant l'import
```powershell
psql -U akig_user -d akig_db -f backend/db/migrations/001_create_property_management.sql
```

#### 2. Contrainte FK viol√©e
```
‚ùå R√©f√©rence FK introuvable: proprietaire_id = 999
```
**Solution** : Le cat√©goriseur signale ces probl√®mes dans les warnings. Corriger les donn√©es ou importer d'abord les parents.

#### 3. Format de donn√©es invalide
```
‚ö†Ô∏è Format email invalide: contact@incomplete
‚ö†Ô∏è Montant n√©gatif: loyer = -500
```
**Solution** : Les warnings sont dans `validation-report.json`. Corriger manuellement les donn√©es sources ou accepter les avertissements.

#### 4. Doublons
```
ON CONFLICT (id) DO UPDATE
```
**Solution** : Le syst√®me g√®re automatiquement les doublons en mettant √† jour les enregistrements existants.

---

## üìä V√©rification Post-Import

### V√©rifier les comptages

```sql
-- Compter les enregistrements par table
SELECT 'owners' AS table_name, COUNT(*) FROM owners
UNION ALL
SELECT 'sites', COUNT(*) FROM sites
UNION ALL
SELECT 'properties', COUNT(*) FROM properties
UNION ALL
SELECT 'tenants', COUNT(*) FROM tenants
UNION ALL
SELECT 'contracts', COUNT(*) FROM contracts
UNION ALL
SELECT 'payments', COUNT(*) FROM payments;
```

### V√©rifier les relations FK

```sql
-- V√©rifier les sites sans propri√©taire
SELECT * FROM sites WHERE owner_id NOT IN (SELECT id FROM owners);

-- V√©rifier les contrats orphelins
SELECT * FROM contracts 
WHERE property_id NOT IN (SELECT id FROM properties)
   OR tenant_id NOT IN (SELECT id FROM tenants);
```

### V√©rifier les donn√©es

```sql
-- Top 10 propri√©taires par nombre de sites
SELECT o.company_name, COUNT(s.id) AS nb_sites
FROM owners o
LEFT JOIN sites s ON s.owner_id = o.id
GROUP BY o.id, o.company_name
ORDER BY nb_sites DESC
LIMIT 10;

-- Total paiements par contrat
SELECT c.id, t.first_name, t.last_name, 
       COUNT(p.id) AS nb_paiements,
       SUM(p.amount) AS total_paye
FROM contracts c
JOIN tenants t ON t.id = c.tenant_id
LEFT JOIN payments p ON p.contract_id = c.id
GROUP BY c.id, t.first_name, t.last_name
ORDER BY total_paye DESC
LIMIT 20;
```

---

## üéì Cas d'Usage Avanc√©s

### Import de plusieurs fichiers CSV

```powershell
# Analyser un r√©pertoire de CSV
python scripts/legacy-import/analyze-archive.py data/csv-exports/

# Le reste est identique
```

### Import d'une base SQLite

```powershell
# Analyser directement une DB SQLite
python scripts/legacy-import/analyze-archive.py data/ancien_systeme.sqlite

# Continuer normalement
```

### Import incr√©mental (ajouts uniquement)

Modifier `import-to-postgres.py` ligne ~150 :
```python
# Changer ON CONFLICT DO UPDATE en ON CONFLICT DO NOTHING
ON CONFLICT (id) DO NOTHING
```

---

## üÜò Support et Troubleshooting

### Activer les logs d√©taill√©s

Modifier les scripts pour ajouter plus de debug :
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Sauvegarder avant import

```powershell
# Backup de la base avant import
pg_dump -U akig_user akig_db > backup_avant_import.sql
```

### Restaurer en cas de probl√®me

```powershell
# Restaurer le backup
psql -U akig_user akig_db < backup_avant_import.sql
```

---

## ‚úÖ Checklist Compl√®te

- [ ] Archive legacy plac√©e dans `c:\AKIG\data/`
- [ ] D√©pendances Python install√©es (`pip install psycopg2-binary`)
- [ ] PostgreSQL lanc√© et accessible
- [ ] Migrations ex√©cut√©es (tables cr√©√©es)
- [ ] √âtape 1 : Analyse termin√©e ‚Üí `analysis-report.json` g√©n√©r√©
- [ ] √âtape 2 : Validation termin√©e ‚Üí fichiers JSON cat√©goris√©s
- [ ] Rapport de validation v√©rifi√© (taux de succ√®s > 95%)
- [ ] √âtape 3a : Dry-run import r√©ussi
- [ ] Backup de la base cr√©√©
- [ ] √âtape 3b : Import r√©el termin√©
- [ ] V√©rification comptages SQL
- [ ] V√©rification relations FK
- [ ] Tests application avec nouvelles donn√©es
- [ ] Archive import dans le syst√®me de backup

---

## üéâ F√©licitations !

Vos donn√©es legacy sont maintenant dans le nouveau syst√®me AKIG !

**Prochaines √©tapes** :
1. Tester toutes les fonctionnalit√©s avec les donn√©es r√©elles
2. Former les utilisateurs sur la nouvelle interface
3. Archiver l'ancien syst√®me (garder en lecture seule pendant 6 mois)
4. Monitorer les performances avec les donn√©es de production

---

**Besoin d'aide ?** Consultez les rapports JSON g√©n√©r√©s ou contactez le support technique.
