#!/usr/bin/env python3
"""
AKIG - Import de Donn√©es Legacy vers PostgreSQL
Import s√©curis√© avec transactions, validation et rollback
Author: AKIG Dev Team
"""

import json
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import psycopg2
from psycopg2 import sql
from psycopg2.extras import execute_batch

class LegacyDataImporter:
    """Importeur de donn√©es legacy vers PostgreSQL"""
    
    # Ordre d'import (respecte les contraintes FK)
    IMPORT_ORDER = [
        ("proprietaires", "owners"),
        ("immeubles", "sites"),
        ("locaux", "properties"),
        ("locataires", "tenants"),
        ("contrats", "contracts"),
        ("loyers", "rent_payments"),
        ("paiements", "payments"),
        ("charges", "charges")
    ]
    
    def __init__(self, database_url: str, categorized_data_dir: str, dry_run: bool = False):
        """
        Initialise l'importeur
        
        Args:
            database_url: URL de connexion PostgreSQL
            categorized_data_dir: R√©pertoire contenant les fichiers JSON cat√©goris√©s
            dry_run: Si True, simule l'import sans √©crire en base
        """
        self.database_url = database_url
        self.data_dir = Path(categorized_data_dir)
        self.dry_run = dry_run
        self.conn = None
        self.cursor = None
        
        self.import_stats = {
            "start_time": datetime.now().isoformat(),
            "dry_run": dry_run,
            "imported": {},
            "errors": {},
            "warnings": []
        }
        
    def connect(self):
        """√âtablit la connexion √† la base de donn√©es"""
        print(f"üîå Connexion √† la base de donn√©es...")
        
        if self.dry_run:
            print("  ‚ö†Ô∏è  MODE DRY-RUN activ√© (aucune modification r√©elle)")
        
        try:
            self.conn = psycopg2.connect(self.database_url)
            self.conn.autocommit = False  # Transactions manuelles
            self.cursor = self.conn.cursor()
            print("  ‚úÖ Connexion √©tablie")
            
            # V√©rifier les tables existantes
            self._check_target_tables()
            
        except Exception as e:
            print(f"  ‚ùå Erreur de connexion: {e}")
            raise
    
    def _check_target_tables(self):
        """V√©rifie que les tables cibles existent"""
        print("\nüîç V√©rification des tables cibles...")
        
        for source_category, target_table in self.IMPORT_ORDER:
            self.cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_name = %s
                )
            """, (target_table,))
            
            exists = self.cursor.fetchone()[0]
            
            if exists:
                print(f"  ‚úì {target_table}")
            else:
                print(f"  ‚ùå Table manquante: {target_table}")
                raise Exception(f"Table {target_table} non trouv√©e. Ex√©cutez les migrations d'abord.")
    
    def import_all(self):
        """Importe toutes les cat√©gories"""
        print("\n" + "=" * 80)
        print("üì¶ IMPORT DES DONN√âES LEGACY")
        print("=" * 80)
        
        try:
            for source_category, target_table in self.IMPORT_ORDER:
                json_file = self.data_dir / f"{source_category}.json"
                
                if not json_file.exists():
                    print(f"\n‚è≠Ô∏è  Fichier non trouv√©: {json_file.name}, passage √† la suite")
                    continue
                
                print(f"\n{'='*60}")
                print(f"üìÇ Import: {source_category} ‚Üí {target_table}")
                print(f"{'='*60}")
                
                self._import_category(source_category, target_table, json_file)
            
            if not self.dry_run:
                print("\n‚úÖ Commit des transactions...")
                self.conn.commit()
                print("  ‚úì Toutes les donn√©es import√©es avec succ√®s")
            else:
                print("\n‚ö†Ô∏è  Rollback (dry-run mode)")
                self.conn.rollback()
            
            self._generate_import_report()
            
        except Exception as e:
            print(f"\n‚ùå ERREUR CRITIQUE: {e}")
            if self.conn:
                print("  ‚Ü©Ô∏è  Rollback de toutes les transactions...")
                self.conn.rollback()
            raise
        finally:
            if self.cursor:
                self.cursor.close()
            if self.conn:
                self.conn.close()
    
    def _import_category(self, source_category: str, target_table: str, json_file: Path):
        """Importe une cat√©gorie de donn√©es"""
        
        # Charger les donn√©es
        with open(json_file, 'r', encoding='utf-8') as f:
            records = json.load(f)
        
        if not records:
            print(f"  ‚ö†Ô∏è  Aucune donn√©e √† importer")
            return
        
        print(f"  üìä {len(records)} enregistrements √† importer")
        
        # Pr√©parer les colonnes et valeurs
        if not records:
            return
        
        # Extraire les colonnes communes (exclure les metadata)
        sample_record = records[0]
        columns = [col for col in sample_record.keys() if not col.startswith('_')]
        
        print(f"  üìã Colonnes: {', '.join(columns)}")
        
        # Pr√©parer la requ√™te INSERT
        placeholders = ', '.join(['%s'] * len(columns))
        insert_query = sql.SQL("""
            INSERT INTO {} ({})
            VALUES ({})
            ON CONFLICT (id) DO UPDATE SET {}
        """).format(
            sql.Identifier(target_table),
            sql.SQL(', ').join(map(sql.Identifier, columns)),
            sql.SQL(placeholders),
            sql.SQL(', ').join([
                sql.SQL("{} = EXCLUDED.{}").format(sql.Identifier(col), sql.Identifier(col))
                for col in columns if col != 'id'
            ])
        )
        
        # Pr√©parer les valeurs
        values_list = []
        errors_count = 0
        
        for idx, record in enumerate(records, 1):
            try:
                values = [record.get(col) for col in columns]
                values_list.append(values)
            except Exception as e:
                errors_count += 1
                if source_category not in self.import_stats["errors"]:
                    self.import_stats["errors"][source_category] = []
                self.import_stats["errors"][source_category].append({
                    "record_index": idx,
                    "error": str(e),
                    "record": record
                })
        
        if errors_count > 0:
            print(f"  ‚ö†Ô∏è  {errors_count} enregistrements avec erreurs (ignor√©s)")
        
        # Import par batch
        if values_list:
            try:
                if self.dry_run:
                    print(f"  üîÑ [DRY-RUN] Importerait {len(values_list)} enregistrements")
                    print(f"  üîç Exemple de requ√™te:")
                    print(f"    {insert_query.as_string(self.conn)[:200]}...")
                else:
                    print(f"  üîÑ Import en cours...")
                    execute_batch(self.cursor, insert_query, values_list, page_size=100)
                    print(f"  ‚úÖ {len(values_list)} enregistrements import√©s")
                
                self.import_stats["imported"][source_category] = {
                    "table": target_table,
                    "count": len(values_list),
                    "errors": errors_count
                }
                
            except Exception as e:
                print(f"  ‚ùå Erreur d'import: {e}")
                raise
    
    def _generate_import_report(self):
        """G√©n√®re le rapport d'import"""
        self.import_stats["end_time"] = datetime.now().isoformat()
        
        report_path = Path("c:/AKIG/scripts/legacy-import/import-report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.import_stats, f, indent=2, ensure_ascii=False)
        
        print("\n" + "=" * 80)
        print("üìä RAPPORT D'IMPORT - R√âSUM√â")
        print("=" * 80)
        
        if self.import_stats["imported"]:
            total_imported = sum(cat["count"] for cat in self.import_stats["imported"].values())
            total_errors = sum(cat["errors"] for cat in self.import_stats["imported"].values())
            
            print(f"\n‚úÖ Total import√©: {total_imported} enregistrements")
            if total_errors > 0:
                print(f"‚ö†Ô∏è  Total erreurs: {total_errors}")
            
            print(f"\nüìÇ D√©tails par cat√©gorie:")
            for category, stats in self.import_stats["imported"].items():
                print(f"  ‚Ä¢ {category} ‚Üí {stats['table']}: {stats['count']} enregistrements")
                if stats['errors'] > 0:
                    print(f"    ‚ö†Ô∏è  {stats['errors']} erreurs")
        
        if self.import_stats["errors"]:
            print(f"\n‚ùå Cat√©gories avec erreurs:")
            for category in self.import_stats["errors"]:
                print(f"  ‚Ä¢ {category}: {len(self.import_stats['errors'][category])} erreurs")
        
        print(f"\nüíæ Rapport sauvegard√©: {report_path}")
        
        print("\n" + "=" * 80)
        print("üéØ PROCHAINES √âTAPES:")
        print("=" * 80)
        print("1. V√©rifier les donn√©es import√©es dans la base")
        print("2. Ex√©cuter les tests de coh√©rence")
        print("3. V√©rifier les relations FK")
        print("4. Tester l'application avec les nouvelles donn√©es")
        print("\n‚ú® Import termin√© !\n")

def main():
    if len(sys.argv) < 3:
        print("Usage: python import-to-postgres.py <database-url> <categorized-data-dir> [--dry-run]")
        print("\nExemple:")
        print("  python import-to-postgres.py")
        print("    postgresql://user:pass@localhost:5432/akig_db")
        print("    c:/AKIG/scripts/legacy-import/categorized-data")
        print("    --dry-run")
        sys.exit(1)
    
    database_url = sys.argv[1]
    categorized_data_dir = sys.argv[2]
    dry_run = "--dry-run" in sys.argv
    
    # V√©rifier que le r√©pertoire existe
    if not Path(categorized_data_dir).exists():
        print(f"‚ùå R√©pertoire introuvable: {categorized_data_dir}")
        sys.exit(1)
    
    importer = LegacyDataImporter(database_url, categorized_data_dir, dry_run=dry_run)
    
    try:
        importer.connect()
        importer.import_all()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Import interrompu par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
