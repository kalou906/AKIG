# =============================================================================
# Kubernetes Horizontal Pod Autoscaler (HPA) - Backend
# =============================================================================
# Automatically scales backend replicas based on CPU, memory, and custom metrics
# Includes gradual scale-down to prevent thrashing and scale-up for traffic spikes
# =============================================================================

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: akig-backend-hpa
  namespace: akig
  labels:
    app: akig
    component: backend
    managed-by: terraform

spec:
  # Target Deployment
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: akig-backend

  # Replica limits
  minReplicas: 3
  maxReplicas: 12

  # ==========================================================================
  # Metrics for Scaling Decisions
  # ==========================================================================
  metrics:
    # CPU Utilization
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 65
      containerResource:
        container: akig-backend
        target:
          type: Utilization
          averageUtilization: 65

    # Memory Utilization
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 75
      containerResource:
        container: akig-backend
        target:
          type: Utilization
          averageUtilization: 75

    # Custom Metric: HTTP Requests Per Second
    - type: Pods
      pods:
        metric:
          name: http_requests_per_second
          selector:
            matchLabels:
              metric_type: rps
        target:
          type: AverageValue
          averageValue: "1000"

    # Custom Metric: Queue Depth (for async job processing)
    - type: Pods
      pods:
        metric:
          name: queue_depth
          selector:
            matchLabels:
              metric_type: queue
        target:
          type: AverageValue
          averageValue: "30"

    # Custom Metric: Database Connection Pool Utilization
    - type: Pods
      pods:
        metric:
          name: db_connection_pool_utilization
          selector:
            matchLabels:
              metric_type: db_pool
        target:
          type: Utilization
          averageUtilization: 70

  # ==========================================================================
  # Scaling Behavior (v2beta2 API)
  # ==========================================================================
  behavior:
    # Scale Up Behavior (aggressive for handling traffic spikes)
    scaleUp:
      stabilizationWindowSeconds: 30
      policies:
        # Increase by 50% of current replicas every 30 seconds
        - type: Percent
          value: 50
          periodSeconds: 30

        # Add 2 pods every 30 seconds
        - type: Pods
          value: 2
          periodSeconds: 30

        # Fastest policy wins (most aggressive scaling)
        - type: Percent
          value: 100
          periodSeconds: 60

      selectPolicy: Max

    # Scale Down Behavior (conservative to prevent thrashing)
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        # Decrease by max 25% of current replicas
        - type: Percent
          value: 25
          periodSeconds: 60

        # Remove max 1 pod every 60 seconds
        - type: Pods
          value: 1
          periodSeconds: 60

      selectPolicy: Min

  # ==========================================================================
  # Template for Pod Disruption Budget
  # Ensures at least 2 pods stay running during disruptions
  # ==========================================================================
  # Note: PDB is defined separately (see pdb-backend.yaml)

# =============================================================================
# Vertical Pod Autoscaler (VPA) Configuration
# Complements HPA by optimizing resource requests/limits
# =============================================================================
---
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: akig-backend-vpa
  namespace: akig
  labels:
    app: akig
    component: backend

spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: akig-backend

  updatePolicy:
    # Update mode: "Auto" = automatically apply recommendations
    updateMode: "Auto"

  resourcePolicy:
    containerPolicies:
      - containerName: akig-backend
        minAllowed:
          cpu: 100m
          memory: 128Mi
        maxAllowed:
          cpu: 2000m
          memory: 2Gi
        controlledResources:
          - cpu
          - memory

# =============================================================================
# Pod Disruption Budget
# Ensures minimum availability during cluster maintenance
# =============================================================================
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: akig-backend-pdb
  namespace: akig
  labels:
    app: akig
    component: backend

spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: akig
      component: backend

# =============================================================================
# Network Policy for Backend
# Restricts traffic to prevent lateral movement
# =============================================================================
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: akig-backend-network-policy
  namespace: akig
  labels:
    app: akig
    component: backend

spec:
  podSelector:
    matchLabels:
      app: akig
      component: backend

  policyTypes:
    - Ingress
    - Egress

  ingress:
    # From Nginx Ingress Controller
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
          podSelector:
            matchLabels:
              app.kubernetes.io/name: ingress-nginx
      ports:
        - protocol: TCP
          port: 4000

    # From monitoring stack (Prometheus, Grafana)
    - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
      ports:
        - protocol: TCP
          port: 4000
        - protocol: TCP
          port: 9090 # Prometheus metrics

    # Internal pod-to-pod communication
    - from:
        - podSelector:
            matchLabels:
              app: akig

  egress:
    # To PostgreSQL
    - to:
        - podSelector:
            matchLabels:
              app: akig
              component: postgres
      ports:
        - protocol: TCP
          port: 5432

    # To Redis
    - to:
        - podSelector:
            matchLabels:
              app: akig
              component: redis
      ports:
        - protocol: TCP
          port: 6379

    # To external APIs (DNS + HTTPS)
    - to:
        - namespaceSelector: {}
      ports:
        - protocol: UDP
          port: 53 # DNS
        - protocol: TCP
          port: 443 # HTTPS

    # Internal service-to-service
    - to:
        - podSelector:
            matchLabels:
              app: akig
      ports:
        - protocol: TCP
          port: 4000
        - protocol: TCP
          port: 3000

# =============================================================================
# ResourceQuota for Backend Namespace
# Prevents resource exhaustion
# =============================================================================
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: akig-backend-quota
  namespace: akig
  labels:
    app: akig
    component: backend

spec:
  hard:
    requests.cpu: "12"
    requests.memory: "24Gi"
    limits.cpu: "24"
    limits.memory: "48Gi"
    pods: "50"
    services: "10"
    services.loadbalancers: "2"

  scopeSelector:
    matchExpressions:
      - operator: In
        scopeName: PriorityClass
        values:
          - high
          - medium
          - low

# =============================================================================
# LimitRange for Backend Pods
# Sets default resource requests/limits
# =============================================================================
---
apiVersion: v1
kind: LimitRange
metadata:
  name: akig-backend-limits
  namespace: akig
  labels:
    app: akig
    component: backend

spec:
  limits:
    # Pod-level limits
    - type: Pod
      max:
        cpu: "2"
        memory: "2Gi"
      min:
        cpu: "100m"
        memory: "128Mi"

    # Container-level limits
    - type: Container
      max:
        cpu: "2"
        memory: "2Gi"
      min:
        cpu: "100m"
        memory: "128Mi"
      default:
        cpu: "500m"
        memory: "512Mi"
      defaultRequest:
        cpu: "250m"
        memory: "256Mi"

    # PVC storage limits
    - type: PersistentVolumeClaim
      max:
        storage: "10Gi"
      min:
        storage: "1Gi"

# =============================================================================
# Monitoring: ServiceMonitor for Prometheus (if using Prometheus Operator)
# =============================================================================
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: akig-backend
  namespace: akig
  labels:
    app: akig
    component: backend

spec:
  selector:
    matchLabels:
      app: akig
      component: backend

  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics

  # Relabel configs for metric scraping
  relabelings:
    - sourceLabels: [__meta_kubernetes_pod_name]
      targetLabel: pod
    - sourceLabels: [__meta_kubernetes_namespace]
      targetLabel: namespace

# =============================================================================
# PrometheusRule for Alerting
# =============================================================================
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: akig-backend-alerts
  namespace: akig
  labels:
    app: akig
    component: backend
    prometheus: kube-prometheus

spec:
  groups:
    - name: akig-backend
      interval: 30s
      rules:
        # High CPU Usage
        - alert: AKIGBackendHighCPU
          expr: |
            (sum(rate(container_cpu_usage_seconds_total{pod=~"akig-backend-.*"}[5m])) by (pod) 
             / sum(container_spec_cpu_quota{pod=~"akig-backend-.*"}) by (pod)) > 0.85
          for: 5m
          labels:
            severity: warning
            component: backend
          annotations:
            summary: "Backend pod {{ $labels.pod }} has high CPU usage"
            description: "CPU usage is {{ $value | humanizePercentage }}"

        # High Memory Usage
        - alert: AKIGBackendHighMemory
          expr: |
            (sum(container_memory_working_set_bytes{pod=~"akig-backend-.*"}) by (pod)
             / sum(container_spec_memory_limit_bytes{pod=~"akig-backend-.*"}) by (pod)) > 0.90
          for: 5m
          labels:
            severity: warning
            component: backend
          annotations:
            summary: "Backend pod {{ $labels.pod }} has high memory usage"
            description: "Memory usage is {{ $value | humanizePercentage }}"

        # Pod Restart Rate
        - alert: AKIGBackendHighRestartRate
          expr: |
            rate(kube_pod_container_status_restarts_total{pod=~"akig-backend-.*"}[1h]) > 0.1
          for: 5m
          labels:
            severity: critical
            component: backend
          annotations:
            summary: "Backend pod {{ $labels.pod }} is restarting frequently"
            description: "Restart rate: {{ $value | humanize }} restarts/hour"

        # HPA Max Replicas Reached
        - alert: AKIGBackendHPAMaxed
          expr: |
            kube_hpa_status_current_replicas{hpa="akig-backend-hpa"} 
            == kube_hpa_status_desired_replicas{hpa="akig-backend-hpa"}
            and kube_hpa_status_desired_replicas{hpa="akig-backend-hpa"} 
            == kube_hpa_spec_max_replicas{hpa="akig-backend-hpa"}
          for: 5m
          labels:
            severity: critical
            component: backend
          annotations:
            summary: "Backend HPA has reached maximum replicas"
            description: "HPA is at maximum ({{ $value }} replicas), may need to increase maxReplicas"
